{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d48b76d",
   "metadata": {},
   "source": [
    "## Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adf3accc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hp\\Anaconda\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout, SpatialDropout1D\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2370d28",
   "metadata": {},
   "source": [
    "**Imports necessary libraries and modules.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139d3ae2",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "291b10ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 10000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d34b32b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 150\n",
    "X_train = pad_sequences(X_train, maxlen=max_len)\n",
    "X_test = pad_sequences(X_test, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82dd93a5",
   "metadata": {},
   "source": [
    "**Loads the IMDb dataset using `imdb.load_data()` and limits the vocabulary to the top 10,000 words.**\n",
    "\n",
    "**Pads the input sequences to a maximum length of 150.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf58035",
   "metadata": {},
   "source": [
    "## Text Decoding Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03fa352c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_to_text(sequence):\n",
    "    word_index = imdb.get_word_index()\n",
    "    reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "    decoded_review = ' '.join([reverse_word_index.get(i - 3, '?') for i in sequence])\n",
    "    return decoded_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "330698ff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1:\n",
      "it was just brilliant so much that i bought the film as soon as it was released for ? and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also ? to the two little boy's that played the ? of norman and paul they were just brilliant children are often left out of the ? list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n",
      "\n",
      "Example 2:\n",
      "the worst ever made the plot is paper thin and ridiculous the acting is an abomination the script is completely laughable the best is the end showdown with the cop and how he worked out who the killer is it's just so damn terribly written the clothes are sickening and funny in equal ? the hair is big lots of boobs ? men wear those cut ? shirts that show off their ? sickening that men actually wore them and the music is just ? trash that plays over and over again in almost every scene there is trashy music boobs and ? taking away bodies and the gym still doesn't close for ? all joking aside this is a truly bad film whose only charm is to look back on the disaster that was the 80's and have a good old laugh at how bad everything was back then\n",
      "\n",
      "Example 3:\n",
      "? ? ? ? ? ? ? ? ? ? this has to be one of the worst films of the 1990s when my friends i were watching this film being the target audience it was aimed at we just sat watched the first half an hour with our jaws touching the floor at how bad it really was the rest of the time everyone else in the theatre just started talking to each other leaving or generally crying into their popcorn that they actually paid money they had ? working to watch this feeble excuse for a film it must have looked like a great idea on paper but on film it looks like no one in the film has a clue what is going on crap acting crap costumes i can't get across how ? this is to watch save yourself an hour a bit of your life\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(f\"Example {i+1}:\\n{sequence_to_text(X_train[i])}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b7ca2e",
   "metadata": {},
   "source": [
    "**Defines a function `sequence_to_text` to decode integer-encoded reviews back to human-readable text.**\n",
    "\n",
    "**Prints three examples of decoded reviews from the training data.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0517f5",
   "metadata": {},
   "source": [
    "##  Model Definition and Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e7eb611",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hp\\Anaconda\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hp\\Anaconda\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_words, 128, input_length=max_len))\n",
    "model.add(SpatialDropout1D(0.3))\n",
    "model.add(Bidirectional(LSTM(100, dropout=0.3, recurrent_dropout=0.3)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448f6194",
   "metadata": {},
   "source": [
    "**Defines a Sequential model with an Embedding layer, SpatialDropout1D, Bidirectional LSTM, and Dense layers.**\n",
    "\n",
    "**Compiles the model using binary crossentropy loss and the Adam optimizer.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ba9d75",
   "metadata": {},
   "source": [
    "##  Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "665482c7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hp\\Anaconda\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hp\\Anaconda\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "782/782 [==============================] - 604s 757ms/step - loss: 0.4352 - accuracy: 0.7964 - val_loss: 0.3411 - val_accuracy: 0.8487\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x183042ce290>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
    "batch_size = 32\n",
    "epochs = 1\n",
    "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,\n",
    "validation_data=(X_test, y_test), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a78cc12",
   "metadata": {},
   "source": [
    "**Sets up early stopping to prevent overfitting during training.**\n",
    "\n",
    "**Fits the model to the training data and validates on the test data.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c9a0ac",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "689c5f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 44s 56ms/step - loss: 0.3411 - accuracy: 0.8487\n",
      "Accuracy: 84.87%\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Accuracy: {accuracy*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04264380",
   "metadata": {},
   "source": [
    "**Evaluates the model on the test data and prints the accuracy.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a13612",
   "metadata": {},
   "source": [
    "##  Making Predictions on New Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6fae87df",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_texts = [\"This movie is great!\", \"The plot is confusing.\", \"Amazing film with brilliant performances.\", \n",
    "             \"This is bad\", \"It is not cold outside today.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ffa59f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and pad the new texts\n",
    "tokenizer = Tokenizer(num_words=max_words, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(new_texts)\n",
    "new_sequences = tokenizer.texts_to_sequences(new_texts)\n",
    "new_padded = pad_sequences(new_sequences, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc13606a",
   "metadata": {},
   "source": [
    "**Defines a list of new texts for sentiment analysis.**\n",
    "\n",
    "**Tokenizes and pads the new texts using the same tokenizer and padding as the training data.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092c6d18",
   "metadata": {},
   "source": [
    "## Displaying Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74d96463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 96ms/step\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "predictions = model.predict(new_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ced3b4e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: 'This movie is great!'\n",
      "Predicted Sentiment: Positive\n",
      "\n",
      "Text: 'The plot is confusing.'\n",
      "Predicted Sentiment: Negative\n",
      "\n",
      "Text: 'Amazing film with brilliant performances.'\n",
      "Predicted Sentiment: Positive\n",
      "\n",
      "Text: 'This is bad'\n",
      "Predicted Sentiment: Negative\n",
      "\n",
      "Text: 'It is not cold outside today.'\n",
      "Predicted Sentiment: Negative\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display predictions\n",
    "for i, text in enumerate(new_texts):\n",
    "    sentiment = \"Positive\" if predictions[i] > 0.7 else \"Negative\"\n",
    "    print(f\"Text: '{text}'\\nPredicted Sentiment: {sentiment}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b55843",
   "metadata": {},
   "source": [
    "**Uses the trained model to predict sentiments for the new texts.**\n",
    "\n",
    "**Displays the original texts along with the model's predicted sentiment (Positive or Negative) based on a threshold of 0.7.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
